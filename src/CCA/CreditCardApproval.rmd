---
title: "UADE - Maestria TIC - Ciencia de Datos - Modelo de predicción para aprobación de Tarjetas de Crédito"
author: "Marcelo Capozzi (LU: 1119183) - Nicolas Gladkoff (LU: 1085075)"
date: "Abril 2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
  html_notebook: default
---

#### GitHub:
https://github.com/ngladkoff/ds-credit-card-approval

#### DataSource:
https://www.kaggle.com/rikdifos/credit-card-approval-prediction


# Introducción

La salud de la industria de tarjetas de crédito se mide no por el número de personas con tarjeta, sino por el número de personas que pagan sus consumos. 

La empresa que nos contrata actualmente toma la decisión respecto a si aprueba o no un crédito basándose en informes comerciales sobre el historial crediticio de la persona solicitante. 

En los casos en que la persona no tenga historial crediticio, o que el historial crediticio sea bueno, el crédito se otorga.

Se busca brindar a la empresa una herramienta adicional que mejore la selección en los casos que no se cuente con información crediticia histórica.


# Objetivo

El presente trabajo busca evaluar si es posible predecir, en base a los datos de una solicitud de tarjeta de crédito, si el crédito tiene una alta probabilidad de quedar impago (créditos malos). 

Para entrenar este modelo de predicción se analizarán los datos de la información histórica y del comportamiento de pago de los clientes pasados y actuales de la entidad.

Considerando que este modelo va a utilizarse solamente para aquellas solicitudes que no cuenten con información crediticia previa, el negocio establece como suficiente que detecte 2 de cada 3 créditos malos. 

No obstante, a pesar de que los créditos malos no son buenos para el negocio, se busca que no se pierdan en este proceso más de 1 de cada 4 créditos buenos.


# Datos

La entidad crediticia nos proporcionó los datos históricos que tienen disponibles, datos que deberán ser analizados para evaluar su calidad y si son suficientes para ayudarnos a resolver el problema.

Se nos proporcionó 2 datasets: 

- application_record.csv: que contiene los datos de las solicitudes de tarjetas de crédito

- credit_record.csv: que contiene la información histórica del comportamiento de pagos

En pos de cumplir la meta propuesta, al set de datos proporcionado vamos a agregarle una variable Objetivo *Approve*. Esta variable se completará analizando el historial crediticio que tuvieron las solicitudes, y tendrá dos valores posibles: 

| Valor | Descripción |
|---|---|
| 1 | Representa un crédito bueno, que debería ser aprobado |
| 0 | Representa un crédito malo, que no debería ser aprobado |

## Diccionario de datos

Descripción de los datasets

***application_record***

| Nombre | Descripción | Observaciones | 
|---|---|---|
| ID | Número de Cliente ||
| CODE_GENDER| Género ||
| FLAG_OWN_CAR | Posee automóvil propio? ||
| FLAG_OWN_REALTY | Es propietario? ||
| CNT_CHILDREN | Cantidad de Hijos || 
| AMT_INCOME_TOTAL | Ingreso Anual (u$d) ||
| NAME_INCOME_TYPE |	Tipo de Ingreso	||
| NAME_EDUCATION_TYPE | Nivel Educativo ||
| NAME_FAMILY_STATUS | Estado Civil ||
| NAME_HOUSING_TYPE | Tipo de Vivienda ||
| DAYS_BIRTH | Días desde la fecha de nacimiento ||
| DAYS_EMPLOYED | Días desde la fecha de inicio laboral ||
| FLAG_MOBIL | Tiene Celular? ||
| FLAG_WORK_PHONE | Dejó Teléfono Laboral?	||
| FLAG_PHONE | Dejó Teléfono Particular? ||
| FLAG_EMAIL | Dejó su Email?	||
| OCCUPATION_TYPE | Actividad Laboral ||
| CNT_FAM_MEMBERS | Cantidad Integrantes de la familia	||

***credit_record***

| Nombre | Descripción | Observaciones | 
|---|---|---|
| ID | Número de Cliente ||
| MONTHS_BALANCE | Mes del registro | El mes al que pertenece el registro es contado hacia atrás, 0 es el mes actual, -1 el anterior y así sucesivamente. |
| STATUS | Estado | *Ver tabla STATUS* |

***STATUS***

| STATUS | Descripción |
|---|---|
| 0 | 1-29 días deudor |
| 1 | 30-59 días deudor |
| 2 | 60-89 días deudor |
| 3 | 90-119 días deudor |
| 4 | 120-149 días deudor |
| 5 | más de 150 días deudor |
| C | canceló las deudas ese mes |
| X | sin deudas ese mes |

***Variables generadas al procesar los datos***

| Nombre | Descripción | Observaciones | 
|---|---|---|
| AGE | Edad ||
| YEARS_EMPLOYED | Años en el empleo ||
| Approved | (Objetivo) El crédito debe o no ser aprobado ||

## Configuración de ambiente y carga de los datos

Configuramos las librerías a utilizar y cargamos los datasets en el ambiente de trabajo.

```{r, message=FALSE}
##################
# Load libraries #
##################
library(ggplot2)
library(dplyr)
library(sqldf)
library(corrplot)
library(rms)
library(Information)
library(grid)
library(ROCR)
library(DMwR)
```

Si los datasets no están en el directorio de trabajo los descargamos:

```{r}
######################
# Download datafiles #
######################

# Set the data directory 
# It will be a subdirectory 'data/' of the current directory
maindir <- getwd()
datadir <- paste(maindir, "data", sep="/")

applRecordURL <- "https://raw.githubusercontent.com/ngladkoff/ds-credit-card-approval/master/data/application_record.csv"
credRecordURL <- "https://raw.githubusercontent.com/ngladkoff/ds-credit-card-approval/master/data/credit_record.csv"

applRecordFile <- paste(datadir, "applRecord.csv", sep="/")
credRecordFile <- paste(datadir, "credRecord.csv", sep="/")

if (!dir.exists(datadir)) {
    print(paste("Creating data directory ", datadir))
    dir.create(datadir)
}

if (!file.exists(applRecordFile)) {
    print("Downloading Application Records")
    download.file(applRecordURL, applRecordFile, method="auto")
} else {
    print(paste("Data file", applRecordFile, "already exists"))
}

if (!file.exists(credRecordFile)) {
    print("Downloading Application Records")
    download.file(credRecordURL, credRecordFile, method="auto")
} else {
    print(paste("Data file", credRecordFile, "already exists"))
}

```

```{r}
#######################
# Load the dataframes #
#######################

dfApplications <- read.csv(applRecordFile)
dfCredits <- read.csv(credRecordFile)

```

Definimos una función que vamos a necesitar mas adelante
```{r}
nplot <- function(plist) {
  n <- length(plist)
  grid.newpage()
  pushViewport(viewport(layout=grid.layout(n,1)))
  vplayout=function(x,y) { viewport(layout.pos.row=x, layout.pos.col=y) }
  for (i in 1:n) {
    print(plist[[i]], vp=vplayout(i,1))
  }
}
```

Definimos una semilla por si usamos generadores de datos aleatoreos, para garantizar reproducibilidad.
```{r}
set.seed(1234)
```


# Análisis Exploratorio de Datos

## 1 - Exámen inicial de los datos

### 1.1 - Dataset: Applications

#### 1.1.1 - Estructura

```{r}
str(dfApplications)
```

En la estructura observamos el tipo de cada variable, observando algunas que necesitan ser convertidas en categóricas:

- FLAG_MOBIL
- FLAG_WORK_PHONE
- FLAG_PHONE
- FLAG_EMAIL

Se observa también que la variable OCCUPATION_TYPE es categórica y tiene muchas categorías. Esto es algo que debemos tener en cuenta al momento de entrenar el modelo, según la bibliografía las regresiones logísticas podrían verse afectadas en su predicción ante este tipo de variables.

Por último, nos llama la atención la variable DAYS_EMPLOYED que tiene valores negativos y positivos, algunos muy grandes (en el rango de los 1000 años)


#### 1.1.2 - Conversión variables categóricas

```{r}
dfApplications$FLAG_MOBIL <- factor(dfApplications$FLAG_MOBIL, ordered=FALSE)
dfApplications$FLAG_WORK_PHONE <- factor(dfApplications$FLAG_WORK_PHONE, ordered=FALSE)
dfApplications$FLAG_PHONE <- factor(dfApplications$FLAG_PHONE, ordered=FALSE)
dfApplications$FLAG_EMAIL <- factor(dfApplications$FLAG_EMAIL, ordered=FALSE)

```

#### 1.1.3 - Summary
```{r}
summary(dfApplications)
```

Se vuelve a observar alguna anormalidad en la variable DAYS_EMPLOYED que deberá ser analizada.

Se observa que la variable FLAG_MOBIL solo tiene una categoría, por lo que ya se puede descartar por no aportar valor al modelo.

La variable OCCUPATION_TYPE además de tener muchas categorías, como ya se había notado anteriormente, parece tener datos incompletos. Deberá ser analizado.

Respecto a la cantidad de hijos y el ingreso total vamos a tener que evaluar la distribución, los máximos y mínimos están muy lejos del promedio y la mediana.

#### 1.1.4 - Búsqueda de IDs duplicados

Para asegurarnos que ambos datasets se puedan juntar una vez procesados debemos verificar no tener IDs duplicados en el dataset de Applications.

```{r}
dfAppIds <- data.frame(table(dfApplications$ID))
cUniAppIds <- dim(dfApplications[unique(dfApplications$ID),])[1]
cDupAppIds <- dim(dfApplications[duplicated(dfApplications$ID),])[1]
cDupAppRecord <- dim(dfApplications[duplicated(dfApplications),])[1]
dfDupAppIds <- dfApplications[duplicated(dfApplications$ID),]
cAppIds <- dim(dfApplications)[1]

print(paste("IDs únicos:", cUniAppIds))
print(paste("IDs duplicados:", cDupAppIds))
print(paste("Records duplicados: ", cDupAppRecord))
print(paste("Total:", cAppIds))
print(paste("Duplicados: %", (round((cDupAppIds*100/cAppIds), digits=2))))

```

Observamos que no tenemos registros duplicados, es decir, que todos sus valores coincidan. Sin embargo, detectamos 47 IDs duplicados. Concluimos que no corresponden a una misma solicitud cargada más de una vez sino solicitudes distintas con la misma numeración.

Por el bajo porcentaje que representan se decide eliminar del análisis estos registros duplicados.

```{r}
dfDupAppIds2 <- data.frame(dfDupAppIds$ID)
dfDupIds <- sqldf("SELECT distinct ID FROM dfApplications WHERE ID in dfDupAppIds2")
dfApplicationsCleaned <- sqldf("SELECT * FROM dfApplications WHERE ID NOT in dfDupAppIds2")
cNewTotal <- dim(dfApplicationsCleaned)[1]
print(paste("Cantidad Anterior - Cantidad Nueva: ",cAppIds - cNewTotal))
```

Validamos que la cantidad nueva tiene 94 registros menos (47 duplicados x 2).


### 1.2 - Dataset: Credits

#### 1.2.1 - Estructura

```{r}
str(dfCredits)
```

Observamos que por cada ID de solicitud se crean varios registros, uno por cada mes, con el estado de la deuda en dicho mes.

Se imprimen los primeros y últimos registros para confirmar:
```{r}
head(dfCredits)
tail(dfCredits)
```

Para poder armar nuestra variable objetivo *Approve* vamos a necesitar reducir estos datos a un solo registro por ID.

#### 1.2.2 - Summary

```{r}
summary(dfCredits)
```

No se observan números fuera de rango dentro de la variable MONTHS_BALANCE.


## 2 - Reducción dataset Credits

### 2.1 - Identificar IDs únicos
```{r}
dfCredIds <- data.frame(table(dfCredits$ID))
```


#### 2.1.1 - Estructura
```{r}
str(dfCredIds)
```

Se observa que este dataset solo cuenta con 45985 IDs únicos. Esto nos indica que de los poco más de 438000 registros del dataset de Applications solo tenemos información de algunos.

#### 2.1.2 - Summary
```{r}
summary(dfCredIds)
```


### 2.2 - Reducir registros

Se decidió que vamos a tomar el estado del último més del que tenemos información. 

Para esto recuperamos primero cual es ese último mes:
```{r}

dfCreditsLastMonth <- sqldf("SELECT ID, MAX(MONTHS_BALANCE) as LAST FROM dfCredits GROUP BY ID order by LAST")
str(dfCreditsLastMonth)

```

Verificamos que la cantidad de registros coincide con el análisis de IDs únicos. 

Continuamos agregando el estádo del crédito en ese último mes.
```{r}
dfCreditsReduced <- sqldf("SELECT t1.ID, t1.LAST, t2.STATUS FROM dfCreditsLastMonth t1 JOIN dfCredits t2 ON t1.ID = t2.ID and t1.LAST = t2.MONTHS_BALANCE")
summary(dfCreditsReduced)
```

Definimos nuestra variable objetivo: *Approve*. Si el estado del crédito en el último mes que se tiene registro no quedó con deuda (estados C, X y 0) se va a establecer un uno, y si quedó en otro de los estados, un cero.

```{r}
dfCreditsReduced$Approve <- ifelse(dfCreditsReduced$STATUS == 'C' | dfCreditsReduced$STATUS == 'X' | dfCreditsReduced$STATUS == '0', 1, 0)
dfCreditsReduced$Approve <- factor(dfCreditsReduced$Approve, ordered = FALSE)
summary(dfCreditsReduced)
print(paste("% Créditos malos: ", round(100 * length(which(dfCreditsReduced$Approve == 0)) / length(which(dfCreditsReduced$Approve == 1)),digits=2)))
```

Se observa que la cantidad de créditos "malos" es de aproximadamente el 1%, que representa un porcentaje bajo de incobrabilidad. Según lo que hemos investigado suele ser lijeramente superior al 3%. 


## 3 - Unificar los datasets

### 3.1 - Unificar
```{r}
dfCreditCard <- merge(dfApplicationsCleaned, dfCreditsReduced, by="ID")
```

### 3.2 - Estructura
```{r}
str(dfCreditCard)
```

### 3.3 - Summary
```{r}
summary(dfCreditCard)
```


### 3.4 - Conclusiones de la unificación

Luego de unir ambos datasets observamos que la cantidad de registros de clientes que poseen información histórica ha disminuido. 

Esto se debe a que no todas las solicitudes de tarjeta de crédito tienen asociado un historial crediticio registrado. 

Para los fines de este análisis, aceptaremos cómo válida esta reducción en el set de datos.
 
```{r}
print(paste("Registros en el historial:", dim(dfCreditsReduced)[1]))
print(paste("Solicitudes de tarjetas de crédito con registros en el historial:", dim(dfCreditCard)[1]))
```


## 4 - Análisis de variables sobre dataset unificado

### 4.1 - Análisis de variables númericas

#### 4.1.1. - Variable: CNT_CHILDREN

##### CNT_CHILDREN

En relación a la variable *CNT_CHILDREN* observaremos la distribución de la cantidad total de hijos en cada barra del siguiente gráfico:

```{r}
ggplot(dfCreditCard) + 
  geom_histogram(
    aes(x=CNT_CHILDREN), 
    fill="steel blue",
    col= "yellow",
    alpha= .6,
    binwidth = 1) + 
  labs(title="Histograma: Cantidad de hijos en Solicitudes", x="Cantidad Hijos", y="Cantidad Solicitudes")
```

Se observa una marcada concentración respeto de la cantidad de hijos cuando dicho valor es menor o igual a 2.

```{r}
summary(dfCreditCard$CNT_CHILDREN)
```

Se observa en el summary la presencia de valores cercanos a 20, pero como puede observarse en el gráfico anterior son outliers, no hay concentración en esas cantidades.

##### CNT_CHILDREN vs APPROVE

Vamos a utilizar el gráfico BoxPlot para tratar de entender como se relacionan la variable CNT_CHILDREN y nuestra variable Objetivo.

```{r}
ggplot(dfCreditCard) + 
  geom_boxplot(aes(x=Approve, y=CNT_CHILDREN), outlier.color = "red", col="yellow", fill="steel blue", alpha=0.6) +
  labs(title="BoxPlot: Calidad Crediticia según Cantidad de Hijos", x="Credito Malo (0) o Bueno (1)", y="Cantidad de Hijos")
```

Observamos que la cantidad de casos aprobados en comparación de los que no, se mantienen en valores similares. 

Vamos a intentar representarlo de manera diferente.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=CNT_CHILDREN, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según cantidad de hijos", x="Cantidad de Hijos", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```


No se observa en el gráfico una relación aparente entre la variable CNT_CHILDREN y la varible objetivo.


#### 4.1.2. - Variable: AMT_INCOME_TOTAL

##### AMT_INCOME_TOTAL

En relación a la variable *AMT_INCOME_TOTAL* observaremos su distribuciónen el siguiente gráfico:

```{r}
ggplot(dfCreditCard) + 
  geom_histogram(
    aes(x=AMT_INCOME_TOTAL), 
    fill="steel blue",
    col= "yellow",
    alpha= .6, bins=10) + 
  labs(title="Histograma: Ingresos", x="Ingreso anual (u$d)", y="Cantidad Solicitudes")
```

Se observa una marcada concentración de solicitudes en un rango medio de ingresos anuales. si bien se observa la presencia de algunas solicitudes con ingresos muy superiores.

```{r}
summary(dfCreditCard$AMT_INCOME_TOTAL)
```

Dentro del rango de los 120000 y los 225000 dolares anuales de ingreso se concentra el 50% de las solicitudes de tarjeta de crédito. Vemos la presencia de valores muy inferiores y muy superiores.


##### AMT_INCOME_TOTAL vs APPROVE

Vamos a utilizar el gráfico BoxPlot para tratar de entender como se relacionan la variable AMT_INCOME_TOTAL y nuestra variable Objetivo.

```{r}
ggplot(dfCreditCard) + 
  geom_boxplot(aes(x=Approve, y=AMT_INCOME_TOTAL), outlier.color = "red", col="yellow", fill="steel blue", alpha=0.6) +
  labs(title="BoxPlot: Calidad Crediticia según Ingresos Anuales", x="Credito Malo (0) o Bueno (1)", y="Ingresos (u$d)")
```

No observamos diferencias significativas en este gráfico. Vamos a intentar representarlo de manera diferente.

```{r}
ggplot(dfCreditCard) +
  geom_histogram(aes(x=AMT_INCOME_TOTAL, fill=Approve), position="fill", alpha=.5, bins=10) +
  labs(title="Creditos Buenos vs Creditos Malos según Ingresos Anuales", x="Ingresos (u$d)", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

Se observa una ligera relación entre las variables. Podría ser un posible predictor.


#### 4.1.3. - Variable: DAYS_BIRTH

##### DAYS_BIRTH

```{r}
summary(dfCreditCard$DAYS_BIRTH)
```

Como se observa, está expresado en días y en negativo, vamos a convertirlo a una escala a la que estamos más acostumbrados a ver, que es expresar la edad en años.

```{r}
dfCreditCard$AGE <- (dfCreditCard$DAYS_BIRTH * -1) %/% 365 
summary(dfCreditCard$AGE)
```

Expresado de esta manera podemos observar que los valores son razonables. 

Observaremos la distribución en el siguiente gráfico:

```{r}
ggplot(dfCreditCard) + 
  geom_histogram(
    aes(x=AGE), 
    fill="steel blue",
    col= "yellow",
    alpha= .6, bins=10) + 
  labs(title="Histograma: Edades", x="Años", y="Cantidad Solicitudes")
```

Observamos una distribución con cierta semejanza a una campana de Gauss (Normal). 
 

##### AGE vs APPROVE

Vamos a utilizar el gráfico BoxPlot para tratar de entender como se relacionan la variable AGE y nuestra variable Objetivo.

```{r}
ggplot(dfCreditCard) + 
  geom_boxplot(aes(x=Approve, y=AGE), outlier.color = "red", col="yellow", fill="steel blue", alpha=0.6) +
  labs(title="BoxPlot: Calidad Crediticia según Edad", x="Credito Malo (0) o Bueno (1)", y="Años")
```

Se observa alguna leve tendencia. Vamos a intentar representarlo de manera diferente.

```{r}
ggplot(dfCreditCard) +
  geom_histogram(aes(x=AGE, fill=Approve), position="fill", alpha=.5, binwidth = 10) +
  labs(title="Creditos Buenos vs Creditos Malos según Edades", x="Años", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

Parece existir una ligera tendencia a que los créditos mejoren a medida que aumenta la edad. Podría ser un posible predictor.


#### 4.1.4. - Variable: DAYS_EMPLOYED

##### DAYS_EMPLOYED

```{r}
summary(dfCreditCard$DAYS_EMPLOYED)
```

Como se observa, está expresado en días y en negativo, vamos a convertirlo a una escala a la que estamos más acostumbrados a ver, que es expresarlo en años. Se observan también valores positivos, que se les va a tener que dar un tratamiento.

```{r}
dfCreditCard$YEARS_EMPLOYED <- (dfCreditCard$DAYS_EMPLOYED * -1) %/% 365 
summary(dfCreditCard$YEARS_EMPLOYED)
```

Expresado de esta manera podemos observar edades negativas. 

Buscamos estos valores:

```{r}
dfNegatives <- filter(dfCreditCard, YEARS_EMPLOYED < 0)
str(dfNegatives)
```

Observamos un número importante de registros con valores negativos (inválidos). Cómo no podemos consultar a negocio que significan estos valores decidimos interpretarlos cómo "antigüedad laboral desconocida", los vamos a reemplazar por la mediana, que es más representativa de la antigüedad que el promedio, justamente por la presencia de estos valores.

```{r}
dfCreditCard$YEARS_EMPLOYED[dfCreditCard$YEARS_EMPLOYED < 0] <- median(dfCreditCard$YEARS_EMPLOYED)

summary(dfCreditCard$YEARS_EMPLOYED)
```

Ahora los valores parecen razonables.

Observaremos la distribución en el siguiente gráfico:

```{r}
ggplot(dfCreditCard) + 
  geom_histogram(
    aes(x=YEARS_EMPLOYED), 
    fill="steel blue",
    col= "yellow",
    alpha= .6, bins=10) + 
  labs(title="Histograma: Antigüedad Laboral", x="Años", y="Cantidad Solicitudes")
```

##### YEARS_EMPLOYED vs APPROVE

Vamos a utilizar el gráfico BoxPlot para tratar de entender como se relacionan la variable YEARS_EMPLOYED y nuestra variable Objetivo.

```{r}
ggplot(dfCreditCard) + 
  geom_boxplot(aes(x=Approve, y=YEARS_EMPLOYED), outlier.color = "red", col="yellow", fill="steel blue", alpha=0.6) +
  labs(title="BoxPlot: Calidad Crediticia según Antigüedad Laboral", x="Credito Malo (0) o Bueno (1)", y="Años")
```

Se observan algunas leves diferencias en este gráfico. Vamos a intentar representarlo de manera diferente.

```{r}
ggplot(dfCreditCard) +
  geom_histogram(aes(x=YEARS_EMPLOYED, fill=Approve), position="fill", alpha=.5, binwidth = 10) +
  labs(title="Creditos Buenos vs Creditos Malos según Antigüedad Laboral", x="Años", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

La leve diferencia notada en el gráfico anterior se mantiene, podría ser un posible predictor.


#### 4.1.5. - Variable: CNT_FAM_MEMBERS

##### CNT_FAM_MEMBERS

En relación a la variable *CNT_FAM_MEMBERS* observaremos la distribución de la cantidad total de integrantes de la familia, en cada barra del siguiente gráfico:

```{r}
ggplot(dfCreditCard) + 
  geom_histogram(
    aes(x=CNT_FAM_MEMBERS), 
    fill="steel blue",
    col= "yellow",
    alpha= .6,
    binwidth = 1) + 
  labs(title="Histograma: Cantidad de Integrantes Familiares", x="Cantidad Integrantes", y="Cantidad Solicitudes")
```

Como era de esperarse se observa una distribución similar a la cantidad de hijos, son variables claramente relacionadas.

##### CNT_FAM_MEMBERS vs APPROVE

Es de esperarse que la relación entre estas dos variables sea similar a lo ya evaluado con cantidad de hijos, se utiliza el gráfico de barras para convalidarlo.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=CNT_FAM_MEMBERS, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según cantidad de miembros familiares", x="Cantidad de integrantes", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

No se verifica una tendencia que justifique incluirlo como predictor.


#### 4.1.6. - Variable: LAST

Es una variable que creamos nosotros para expresar el último período del cual tenemos datos, sirvió de variable intermedia para calcular la situación crediticia. No sirve como predictor.


### 4.2 - Correlación de variables numéricas

Mediante un gráfico de correlación de las variables numéricas vamos a analizar como se relacionan entre ellas.

```{r}
dfcor <- select_if(dfCreditCard, is.numeric)
dfcor <- select(dfcor, -ID, -LAST, -DAYS_EMPLOYED, -DAYS_BIRTH)
cm <- cor(dfcor)
corrplot(cm, method = "number", type = "upper")
```


Observamos en el gráfico que Cantidad de Hijos y Cantidad de Miembros Familiares están muy relaionados, nos parece más amplio el concepto de Miembros Familiares si hubiera que  seleccionarlo como predictor.

No observamos correlaciones significativas entre el resto de las variables.


### 4.3 - Análisis de variables categóricas

#### 4.3.1 - Variable: CODE_GENDER

##### CODE_GENDER

Para conocere la distribución de la muestra graficamos con barras las 2 categorías:

```{r}
ggplot(dfCreditCard) + 
  geom_bar(
    aes(x=CODE_GENDER), 
    stat="count",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Genero", x="Genero", y="Cantidad Solicitudes") +
    coord_flip()
```

Se observa que la muestra contiene aproximadamente dos tercios de mujeres. Evaluar si es algo que podría sesgar el modelo.


##### CODE_GENDER vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=CODE_GENDER, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según genero", x="Genero", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

A pesar que la muestra contenía mayor cantidad de solicitudes del sexo femenino, la distribución respecto a la calidad crediticia es similar a las solicitudes presentadas por el sexo masculino. No parece existir una relación entre el genero y la calidad crediticia.


#### 4.3.2 - Variable: FLAG_OWN_CAR

##### FLAG_OWN_CAR

Para conocere la distribución de la muestra graficamos con barras las 2 categorías:

```{r}
ggplot(dfCreditCard) + 
  geom_bar(
    aes(x=FLAG_OWN_CAR), 
    stat="count",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Auto Propio", x="Auto propio", y="Cantidad Solicitudes") +
    coord_flip()
```


##### FLAG_OWN_CAR vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=FLAG_OWN_CAR, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según si tienen o no Auto Propio", x="No / SI", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

No parece existir una relación entre el Auto Propio y la calidad crediticia.


#### 4.3.3 - Variable: FLAG_OWN_REALTY

##### FLAG_OWN_REALTY

Para conocere la distribución de la muestra graficamos con barras las 2 categorías:

```{r}
ggplot(dfCreditCard) + 
  geom_bar(
    aes(x=FLAG_OWN_REALTY), 
    stat="count",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Casa Propia", x="Casa propia", y="Cantidad Solicitudes") +
    coord_flip()
```


##### FLAG_OWN_REALTY vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=FLAG_OWN_REALTY, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según si tienen o no Casa Propia", x="NO / SI", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

Parecería existir alguna tendencia a favor de los que poseen casa propia, podría ser un posible predictor.


#### 4.3.4 - Variable: FLAG_MOBIL

##### FLAG_MOBIL

Para conocere la distribución de la muestra graficamos con barras las 2 categorías:

```{r}
ggplot(dfCreditCard) + 
  geom_bar(
    aes(x=FLAG_MOBIL), 
    stat="count",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Tenencia Celular", x="Celular", y="Cantidad Solicitudes") +
    coord_flip()
```

Como ya habíamos mencionado anteriormente, se observa que todos las solicitudes tienen Teléfono Celular, no nos sirve para la predicción.


#### 4.3.5 - Variable: FLAG_WORK_PHONE

##### FLAG_WORK_PHONE

Para conocere la distribución de la muestra graficamos con barras las 2 categorías:

```{r}
ggplot(dfCreditCard) + 
  geom_bar(
    aes(x=FLAG_WORK_PHONE), 
    stat="count",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Telefono Laboral", x="Telefono Laboral", y="Cantidad Solicitudes") +
    coord_flip()
```


##### FLAG_WORK_PHONE vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=FLAG_WORK_PHONE, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según si dejaron o no el teléfono laboral", x="NO / SI", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

Parece existir una ligera diferencia, podría ser un posible predictor.


#### 4.3.6 - Variable: FLAG_PHONE

##### FLAG_PHONE

Para conocere la distribución de la muestra graficamos con barras las 2 categorías:

```{r}
ggplot(dfCreditCard) + 
  geom_bar(
    aes(x=FLAG_PHONE), 
    stat="count",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Telefono Personal", x="Telefono Personal", y="Cantidad Solicitudes") +
    coord_flip()
```


##### FLAG_PHONE vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=FLAG_PHONE, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según si dejaron o no el teléfono personal", x="NO / SI", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

No parece existir una relación entre el teléfono personal y la calidad crediticia.


#### 4.3.7 - Variable: FLAG_EMAIL

##### FLAG_EMAIL

Para conocere la distribución de la muestra graficamos con barras las 2 categorías:

```{r}
ggplot(dfCreditCard) + 
  geom_bar(
    aes(x=FLAG_EMAIL), 
    stat="count",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Email", x="Email", y="Cantidad Solicitudes") +
    coord_flip()
```


##### FLAG_EMAIL vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=FLAG_EMAIL, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según si dejaron o no el email", x="NO / SI", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

Parece existir una muy ligera diferencia, podría ser un posible predictor.


#### 4.3.8 - Variable: NAME_INCOME_TYPE

##### NAME_INCOME_TYPE

Para conocere la distribución de la muestra graficamos con barras diferentes categorías:

```{r}
catIncomeType <- table(dfCreditCard$NAME_INCOME_TYPE)
dfCatIncomeType <- as.data.frame(catIncomeType)
names(dfCatIncomeType) <- c("Categoria","Cantidad")

# Ordenamos
dfCatIncomeType <- transform(dfCatIncomeType, Categoria=reorder(Categoria, Cantidad))

ggplot(dfCatIncomeType) + 
  geom_bar(
    aes(x=Categoria, y=Cantidad), 
    stat="identity",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Tipo de Ingreso", x="Categoría", y="Cantidad Solicitudes") +
    coord_flip()
```


##### NAME_INCOME_TYPE vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=NAME_INCOME_TYPE, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según Tipo de Ingreso", x="Categoría", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

Podría existir alguna relación entre las variables, aunque la diferencia observada en la categoría estudiantes debe ser tenida en cuenta en el contexto observado en el gráfico anterior, donde vemos que las solicitudes de estudiantes son insignificantes en la muestra. Podría ser un posible predictor.


#### 4.3.9 - Variable: NAME_EDUCATION_TYPE

##### NAME_EDUCATION_TYPE

Para conocere la distribución de la muestra graficamos con barras diferentes categorías:

```{r}
catIncomeType <- table(dfCreditCard$NAME_EDUCATION_TYPE)
dfCatIncomeType <- as.data.frame(catIncomeType)
names(dfCatIncomeType) <- c("Categoria","Cantidad")

# Ordenamos
dfCatIncomeType <- transform(dfCatIncomeType, Categoria=reorder(Categoria, Cantidad))

ggplot(dfCatIncomeType) + 
  geom_bar(
    aes(x=Categoria, y=Cantidad), 
    stat="identity",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Nivel de Educación", x="Categoría", y="Cantidad Solicitudes") +
    coord_flip()
```


##### NAME_EDUCATION_TYPE vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
print(levels(dfCreditCard$NAME_EDUCATION_TYPE))
```


```{r}
dfCreditCard$NAME_EDUCATION_TYPE <- factor(dfCreditCard$NAME_EDUCATION_TYPE, levels = c("Lower secondary","Secondary / secondary special","Incomplete higher", "Higher education", "Academic degree"), ordered = TRUE)

ggplot(dfCreditCard) +
  geom_bar(aes(x=NAME_EDUCATION_TYPE, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según Nivel de Educación", x="Categoría", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green"))
```

Visualizamos que podría existir una relación entre el nivel de educación y la calidad crediticia. Podría ser un posible predictor.


#### 4.3.10 - Variable: NAME_FAMILY_STATUS

##### NAME_FAMILY_STATUS

Para conocere la distribución de la muestra graficamos con barras diferentes categorías:

```{r}
catIncomeType <- table(dfCreditCard$NAME_FAMILY_STATUS)
dfCatIncomeType <- as.data.frame(catIncomeType)
names(dfCatIncomeType) <- c("Categoria","Cantidad")

# Ordenamos
dfCatIncomeType <- transform(dfCatIncomeType, Categoria=reorder(Categoria, Cantidad))

ggplot(dfCatIncomeType) + 
  geom_bar(
    aes(x=Categoria, y=Cantidad), 
    stat="identity",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Estado Civil", x="Categoría", y="Cantidad Solicitudes") +
    coord_flip()
```


##### NAME_FAMILY_STATUS vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=NAME_FAMILY_STATUS, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según Estado Civil", x="Categoría", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green")) +
    coord_flip()
```


Se visualiza una ligera relación entre las variables. Podría ser un posible predictor.


#### 4.3.11 - Variable: NAME_HOUSING_TYPE

##### NAME_HOUSING_TYPE

Para conocere la distribución de la muestra graficamos con barras diferentes categorías:

```{r}
catIncomeType <- table(dfCreditCard$NAME_HOUSING_TYPE)
dfCatIncomeType <- as.data.frame(catIncomeType)
names(dfCatIncomeType) <- c("Categoria","Cantidad")

# Ordenamos
dfCatIncomeType <- transform(dfCatIncomeType, Categoria=reorder(Categoria, Cantidad))

ggplot(dfCatIncomeType) + 
  geom_bar(
    aes(x=Categoria, y=Cantidad), 
    stat="identity",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Tipo de Vivienda", x="Categoría", y="Cantidad Solicitudes") +
    coord_flip()
```


##### NAME_HOUSING_TYPE vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=NAME_HOUSING_TYPE, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según Tipo Vivienda", x="Categoría", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green")) +
    coord_flip()
```


Se visualiza una relación entre las variables. Podría ser un posible predictor.


#### 4.3.12 - Variable: OCCUPATION_TYPE

##### OCCUPATION_TYPE

Como se observó en el summary, la categoría tiene datos incompletos.
```{r}
summary(dfCreditCard$OCCUPATION_TYPE)
```

No podemos consultar a negocio si son solicitudes incompletas o representa la categoría "Otros". A los fines del ejercicio se decide etiquetarlos como "Otros".

```{r}
levels(dfCreditCard$OCCUPATION_TYPE)[levels(dfCreditCard$OCCUPATION_TYPE) == ""] <- "Other"
summary(dfCreditCard$OCCUPATION_TYPE)
```

Para conocere la distribución de la muestra graficamos con barras diferentes categorías:

```{r}
catIncomeType <- table(dfCreditCard$OCCUPATION_TYPE)
dfCatIncomeType <- as.data.frame(catIncomeType)
names(dfCatIncomeType) <- c("Categoria","Cantidad")

# Ordenamos
dfCatIncomeType <- transform(dfCatIncomeType, Categoria=reorder(Categoria, Cantidad))

ggplot(dfCatIncomeType) + 
  geom_bar(
    aes(x=Categoria, y=Cantidad), 
    stat="identity",
    fill="steel blue",
    col= "yellow",
    alpha= .6) + 
    labs(title="Barras: Distribución por Actividad Laboral", x="Categoría", y="Cantidad Solicitudes") +
    coord_flip()
```

En esta variable existen muchas categorías. Se deberá evaluar si afecta o no al modelo.

##### OCCUPATION_TYPE vs APPROVE

Verificamos si podría existir alguna relación entre ambas variables mediante un gráfico de barras apiladas.

```{r}
ggplot(dfCreditCard) +
  geom_bar(aes(x=OCCUPATION_TYPE, fill=Approve), position="fill", alpha=.5) +
  labs(title="Creditos Buenos vs Creditos Malos según Actividad Laboral", x="Categoría", y="%") +
  scale_fill_manual(values= c("0"= "red", "1"="green")) +
    coord_flip()
```

Se visualiza una relación entre las variables. Podría ser un posible predictor.


# Construcción del Modelo Predictivo

## 1 - Preparar los datasets de Training y de Testing

Se observa en la variable objetivo que la muestra está muy desbalanceada. 

Se decidió aplicar la técnica SMOTE (Synthetic Minority Over-Sampling Technique) para mejorar el balance.

```{r}
dfCreditCardSMOTE <- SMOTE(Approve ~ ., dfCreditCard, perc.over = 500, k=5, perc.under=150)
str(dfCreditCardSMOTE)
summary(dfCreditCardSMOTE)
```


Dividimos el set de datos en un 80% para entrenamiento y un 20% para prueba.

```{r}
muestra <- floor(nrow(dfCreditCardSMOTE) * 0.8)
trainingIndex <- sample(nrow(dfCreditCardSMOTE), muestra, replace=FALSE)
testIndex <- seq_len(nrow(dfCreditCardSMOTE))[!(seq_len(nrow(dfCreditCardSMOTE)) %in% trainingIndex)]

dfTrainLR <- dfCreditCardSMOTE[trainingIndex,]
dfTestLR <- dfCreditCardSMOTE[testIndex,]
```


## 2 - Fittiamos el modelo de Regresión Logística

Como el problema planteado es de clasificación binaria, es decir intentamos predecir una variable dicotómica, el modelo a probar primero es la Regresión Logística.

### 2.1 - Seleccionamos Predictores en base al análisis

Como primera aproximación vamos a utilizar como predictor la variable *OCCUPATION_TYPE* que es la que mayor relación con la variable objetivo mostraba en los gráficos.

```{r}
objetivo <- "Approve"
predictores <- c("OCCUPATION_TYPE")
```

### 2.2 - Creamos la formula del modelo

```{r}
formula <- paste(objetivo, paste(predictores, collapse = " + "), sep=" ~ ")
print(formula)
```

### 2.3 - Entrenamos el modelo

```{r}
modeloLR <- glm(formula, data=dfTrainLR, family=binomial(link="logit"))
```

#### 2.3.1 - Visualizamos el summary del modelo

```{r}
summary(modeloLR)
```


#### 2.3.2 - Evaluamos el modelo

##### 2.3.2.1 - Plotear distribución de predicciones

```{r}
dfTrainLR$pred <- predict(modeloLR, newdata= dfTrainLR, type="response")
dfTestLR$pred <- predict(modeloLR, newdata= dfTestLR, type="response")

ggplot(dfTrainLR) + 
  geom_density(aes(x=pred, colour=as.factor(Approve), linetype=as.factor(Approve))) +
  xlab("Predicción") + 
  ylab("Densidad") +
  theme_bw()
```

Se observan los los picos bien definidos, pero mucho ruido dentro de cada categoría.


##### 2.3.2.2 - Matriz de Confusión

Probamos con un umbral del 55%.

```{r}
thresh <- 0.55

predObj <-prediction(dfTrainLR$pred, dfTrainLR$Approve)
precObj <- performance(predObj, measure = "prec")
recObj <- performance(predObj, measure = "rec")

precision <- (precObj@y.values)[[1]]
prec.x <- (precObj@x.values)[[1]]
recall <- (recObj@y.values)[[1]]

pnull <- (length(which(dfTrainLR$Approve == 1)) / length(which(dfTrainLR$Approve != 2)))
pnull

ctab.test <- table(prediccion=as.numeric(dfTestLR$pred > thresh), datos=dfTestLR$Approve)
ctab.test

precision <- ctab.test[2,2]/sum(ctab.test[2,])
paste("Precision:", precision)

recall <- ctab.test[2,2]/sum(ctab.test[,2])
paste("Recall:",recall)

enrich <- precision / pnull
paste("Enrich:",enrich)
```

##### 2.3.2.3 - Curva ROC

Antes de decidir ajustar el umbral graficamos la curva ROC para entender las capacidades de predicción del modelo.

```{r}
sensObj <- performance(predObj, measure="sens")
specObj <- performance(predObj, measure="spec")
sensitivity <- (sensObj@y.values)[[1]]
specificity <- (specObj@y.values)[[1]]

dfplot <- data.frame(specm1=1-specificity, sens=sensitivity)
fig <- ggplot(dfplot, aes(x=specm1, y=sens))
fig <- fig + geom_line(color="red", size=1.25)
fig <- fig + geom_abline(aes(slope=1, intercept=0))
fig <- fig + theme_bw()
fig <- fig + xlab("1 - Especificidad")
fig <- fig + ylab("Sensibilidad")
fig
```

La capacidad de predicción de este modelo es muy baja. Vamos a Reentrenar el modelo con mayor cantidad de variables.


### 2.4 - Probamos re-entrenar el modelo

Del resto de los predictores nos parece que van a estar relacionados con OCCUPATION_TYPE los siguientes : NAME_EDUCATION_TYPE, NAME_HOUSING_TYPE y NAME_INCOME_TYPE, no los vamos a usar como predictores. 

Vamos a probar re-entrenar el modelo con los siguientes predictores

```{r}
predictores <- c("OCCUPATION_TYPE", "AGE", "FLAG_WORK_PHONE", "FLAG_EMAIL", "NAME_FAMILY_STATUS", "YEARS_EMPLOYED", "FLAG_OWN_REALTY", "AMT_INCOME_TOTAL")
print("Predictores:")
print(predictores)
```

```{r}
formula <- paste(objetivo, paste(predictores, collapse = " + "), sep=" ~ ")
modeloLR <- glm(formula, data=dfTrainLR, family=binomial(link="logit"))
```

Visualizamos el summary del modelo

```{r}
summary(modeloLR)
```

Salvo EMAIL, el resto parecen ser buenos predictores. Reentrenemos el modelo excluyendo esa variable.

```{r}
predictores <- c("OCCUPATION_TYPE", "AGE", "FLAG_WORK_PHONE", "NAME_FAMILY_STATUS", "YEARS_EMPLOYED", "FLAG_OWN_REALTY", "AMT_INCOME_TOTAL")
print("Predictores:")
print(predictores)
```


```{r}
formula <- paste(objetivo, paste(predictores, collapse = " + "), sep=" ~ ")
modeloLR <- glm(formula, data=dfTrainLR, family=binomial(link="logit"))
```

Visualizamos el summary del modelo

```{r}
summary(modeloLR)
```

Visualizamos el Factor de Inflación de Varianza:

```{r}
vif(modeloLR)
```

Para todas las variables es menor a 5, es decir no están correlacionadas.


#### 2.4.1 - Evaluamos el modelo

##### 2.4.1.1 - Plotear distribución de predicciones

```{r}
dfTrainLR$pred <- predict(modeloLR, newdata= dfTrainLR, type="response")
dfTestLR$pred <- predict(modeloLR, newdata= dfTestLR, type="response")

ggplot(dfTrainLR) + 
  geom_density(aes(x=pred, colour=as.factor(Approve), linetype=as.factor(Approve))) +
  xlab("Predicción") + 
  ylab("Densidad") +
  theme_bw()
```

Se observan los los picos bien definidos, disminuyó el ruido dentro de cada categoría.


##### 2.4.1.2 - Matriz de Confusión

Probamos con un umbral del 55%.

```{r}
thresh <- 0.55

predObj <-prediction(dfTrainLR$pred, dfTrainLR$Approve)
precObj <- performance(predObj, measure = "prec")
recObj <- performance(predObj, measure = "rec")

precision <- (precObj@y.values)[[1]]
prec.x <- (precObj@x.values)[[1]]
recall <- (recObj@y.values)[[1]]

pnull <- (length(which(dfTrainLR$Approve == 1)) / length(which(dfTrainLR$Approve != 2)))
pnull

ctab.test <- table(prediccion=as.numeric(dfTestLR$pred > thresh), datos=dfTestLR$Approve)
ctab.test

precision <- ctab.test[2,2]/sum(ctab.test[2,])
paste("Precision:", precision)

recall <- ctab.test[2,2]/sum(ctab.test[,2])
paste("Recall:",recall)

enrich <- precision / pnull
paste("Enrich:",enrich)
```

##### 2.4.1.3 - Curva ROC

Antes de decidir ajustar el umbral graficamos la curva ROC para entender las capacidades de predicción del modelo.

```{r}
sensObj <- performance(predObj, measure="sens")
specObj <- performance(predObj, measure="spec")
sensitivity <- (sensObj@y.values)[[1]]
specificity <- (specObj@y.values)[[1]]

dfplot <- data.frame(specm1=1-specificity, sens=sensitivity)
fig <- ggplot(dfplot, aes(x=specm1, y=sens))
fig <- fig + geom_line(color="red", size=1.25)
fig <- fig + geom_abline(aes(slope=1, intercept=0))
fig <- fig + theme_bw()
fig <- fig + xlab("1 - Especificidad")
fig <- fig + ylab("Sensibilidad")
fig
```

Observamos que este modelo tiene una leve mejora en las capacidades de predicción con respecto al modelo anterior.


### 2.5 - Probamos re-entrenar el modelo para comparar

Además de la variable EMAIL descartada por no funcionar bien como predictor nos quedan las variables que podrían estar relacionadas con OCCUPATION_TYPE. Vamos a probar que pasa si incluimos esas variables.

```{r}
predictores <- c("OCCUPATION_TYPE", "AGE", "FLAG_WORK_PHONE", "NAME_FAMILY_STATUS", "YEARS_EMPLOYED", "FLAG_OWN_REALTY", "AMT_INCOME_TOTAL", "NAME_INCOME_TYPE", "NAME_EDUCATION_TYPE", "NAME_HOUSING_TYPE")
print("Predictores:")
print(predictores)
```

```{r}
formula <- paste(objetivo, paste(predictores, collapse = " + "), sep=" ~ ")
modeloLR <- glm(formula, data=dfTrainLR, family=binomial(link="logit"))
```

Visualizamos el summary del modelo

```{r}
summary(modeloLR)
```

Al incorporarlas bajó la capacidad de predicción del resto de las variables.

Visualizamos el Factor de Inflación de Varianza:

```{r}
vif(modeloLR)
```

La variable NAME_EDUCATION_TYPE parece ser la más relacionada, probamos excluirla del modelo.


```{r}
predictores <- c("OCCUPATION_TYPE", "AGE", "FLAG_WORK_PHONE", "NAME_FAMILY_STATUS", "YEARS_EMPLOYED", "FLAG_OWN_REALTY", "AMT_INCOME_TOTAL", "NAME_INCOME_TYPE", "NAME_HOUSING_TYPE")
print("Predictores:")
print(predictores)
```

```{r}
formula <- paste(objetivo, paste(predictores, collapse = " + "), sep=" ~ ")
modeloLR <- glm(formula, data=dfTrainLR, family=binomial(link="logit"))
```

Visualizamos el summary del modelo

```{r}
summary(modeloLR)
```

Visualizamos el Factor de Inflación de Varianza:

```{r}
vif(modeloLR)
```

Para todas las variables es menor a 5, es decir no están correlacionadas.


#### 2.5.1 - Evaluamos el modelo

##### 2.5.1.1 - Plotear distribución de predicciones

```{r}
dfTrainLR$pred <- predict(modeloLR, newdata= dfTrainLR, type="response")
dfTestLR$pred <- predict(modeloLR, newdata= dfTestLR, type="response")

ggplot(dfTrainLR) + 
  geom_density(aes(x=pred, colour=as.factor(Approve), linetype=as.factor(Approve))) +
  xlab("Predicción") + 
  ylab("Densidad") +
  theme_bw()
```

Se observan los los picos bien definidos, disminuyó un poco el ruido dentro de cada categoría.


##### 2.5.1.2 - Matriz de Confusión

Probamos con un umbral del 55%.

```{r}
thresh <- 0.55

predObj <-prediction(dfTrainLR$pred, dfTrainLR$Approve)
precObj <- performance(predObj, measure = "prec")
recObj <- performance(predObj, measure = "rec")

precision <- (precObj@y.values)[[1]]
prec.x <- (precObj@x.values)[[1]]
recall <- (recObj@y.values)[[1]]

pnull <- (length(which(dfTrainLR$Approve == 1)) / length(which(dfTrainLR$Approve != 2)))
pnull

ctab.test <- table(prediccion=as.numeric(dfTestLR$pred > thresh), datos=dfTestLR$Approve)
ctab.test

precision <- ctab.test[2,2]/sum(ctab.test[2,])
paste("Precision:", precision)

recall <- ctab.test[2,2]/sum(ctab.test[,2])
paste("Recall:",recall)

enrich <- precision / pnull
paste("Enrich:",enrich)
```

##### 2.5.1.3 - Curva ROC

Antes de decidir ajustar el umbral graficamos la curva ROC para entender las capacidades de predicción del modelo.

```{r}
sensObj <- performance(predObj, measure="sens")
specObj <- performance(predObj, measure="spec")
sensitivity <- (sensObj@y.values)[[1]]
specificity <- (specObj@y.values)[[1]]

dfplot <- data.frame(specm1=1-specificity, sens=sensitivity)
fig <- ggplot(dfplot, aes(x=specm1, y=sens))
fig <- fig + geom_line(color="red", size=1.25)
fig <- fig + geom_abline(aes(slope=1, intercept=0))
fig <- fig + theme_bw()
fig <- fig + xlab("1 - Especificidad")
fig <- fig + ylab("Sensibilidad")
fig
```

Observamos que este modelo tiene una leve mejora en las capacidades de predicción con respecto al modelo anterior.


### 2.6 - Probamos re-entrenar el modelo con una variante mas

Como indica la bibliografía, la regresión logística pierde capacidad de predicción con variables categóricas con muchos niveles. Como la variable OCCUPATION_TYPE tiene 19 niveles, vamos a probar sacarla para ver que pasa.

```{r}
predictores <- c("AGE", "FLAG_WORK_PHONE", "NAME_FAMILY_STATUS", "YEARS_EMPLOYED", "FLAG_OWN_REALTY", "AMT_INCOME_TOTAL", "NAME_INCOME_TYPE", "NAME_HOUSING_TYPE")
print("Predictores:")
print(predictores)
```

```{r}
formula <- paste(objetivo, paste(predictores, collapse = " + "), sep=" ~ ")
modeloLR <- glm(formula, data=dfTrainLR, family=binomial(link="logit"))
```

Visualizamos el summary del modelo

```{r}
summary(modeloLR)
```

Visualizamos el Factor de Inflación de Varianza:

```{r}
vif(modeloLR)
```

#### 2.6.1 - Evaluamos el modelo

##### 2.6.1.1 - Plotear distribución de predicciones

```{r}
dfTrainLR$pred <- predict(modeloLR, newdata= dfTrainLR, type="response")
dfTestLR$pred <- predict(modeloLR, newdata= dfTestLR, type="response")

ggplot(dfTrainLR) + 
  geom_density(aes(x=pred, colour=as.factor(Approve), linetype=as.factor(Approve))) +
  xlab("Predicción") + 
  ylab("Densidad") +
  theme_bw()
```

Se observa que se produce más ruido en especial en la curva para los créditos de mala calidad (Approve=0)

##### 2.6.1.2 - Matriz de Confusión

Probamos con un umbral del 50%.

```{r}
thresh <- 0.50

predObj <-prediction(dfTrainLR$pred, dfTrainLR$Approve)
precObj <- performance(predObj, measure = "prec")
recObj <- performance(predObj, measure = "rec")

precision <- (precObj@y.values)[[1]]
prec.x <- (precObj@x.values)[[1]]
recall <- (recObj@y.values)[[1]]

pnull <- (length(which(dfTrainLR$Approve == 1)) / length(which(dfTrainLR$Approve != 2)))
pnull

ctab.test <- table(prediccion=as.numeric(dfTestLR$pred > thresh), datos=dfTestLR$Approve)
ctab.test

precision <- ctab.test[2,2]/sum(ctab.test[2,])
paste("Precision:", precision)

recall <- ctab.test[2,2]/sum(ctab.test[,2])
paste("Recall:",recall)

enrich <- precision / pnull
paste("Enrich:",enrich)
```

##### 2.6.1.3 - Curva ROC

Antes de decidir ajustar el umbral graficamos la curva ROC para entender las capacidades de predicción del modelo.

```{r}
sensObj <- performance(predObj, measure="sens")
specObj <- performance(predObj, measure="spec")
sensitivity <- (sensObj@y.values)[[1]]
specificity <- (specObj@y.values)[[1]]

dfplot <- data.frame(specm1=1-specificity, sens=sensitivity)
fig <- ggplot(dfplot, aes(x=specm1, y=sens))
fig <- fig + geom_line(color="red", size=1.25)
fig <- fig + geom_abline(aes(slope=1, intercept=0))
fig <- fig + theme_bw()
fig <- fig + xlab("1 - Especificidad")
fig <- fig + ylab("Sensibilidad")
fig
```

Comparando la curva ROC observamos que el modelo perdió capacidades de predicción.


## 3 - Ajustamos el umbral del modelo seleccionado (2.5)

### 3.1 - Rearmamos el modelo

```{r}
predictores <- c("OCCUPATION_TYPE", "AGE", "FLAG_WORK_PHONE", "NAME_FAMILY_STATUS", "YEARS_EMPLOYED", "FLAG_OWN_REALTY", "AMT_INCOME_TOTAL", "NAME_INCOME_TYPE", "NAME_HOUSING_TYPE")
formula <- paste(objetivo, paste(predictores, collapse = " + "), sep=" ~ ")
modeloLR <- glm(formula, data=dfTrainLR, family=binomial(link="logit"))
```

### 3.2 - Graficamos la precisión y la exhaustividad

```{r}
predObj <-prediction(dfTrainLR$pred, dfTrainLR$Approve)
precObj <- performance(predObj, measure = "prec")
recObj <- performance(predObj, measure = "rec")

precision <- (precObj@y.values)[[1]]
prec.x <- (precObj@x.values)[[1]]
recall <- (recObj@y.values)[[1]]

pnull <- (length(which(dfTrainLR$Approve == 1)) / length(which(dfTrainLR$Approve != 2)))
pnull

# Data for the plot
dfplot <- data.frame(threshold=prec.x, precision=precision, recall=recall)

p1 <- ggplot(dfplot, aes(x=threshold)) +
  geom_line(aes(y=precision/pnull)) +
  xlab("Umbral") +
  ylab("Precisión / P_0")

p2 <- ggplot(dfplot, aes(x=threshold)) +
  geom_line(aes(y=recall)) +
  xlab("Umbral") +
  ylab("Exhaustividad")

nplot(list(p1, p2))
```

### 3.2 - Creamos la matriz de confusión

Tomamos un umbral del 50% para ir ajustando.
```{r}
thresh <- 0.50
ctab.test <- table(prediccion=as.numeric(dfTestLR$pred > thresh), datos=dfTestLR$Approve)
ctab.test

precision <- ctab.test[2,2]/sum(ctab.test[2,])
paste("Precision:", precision)

recall <- ctab.test[2,2]/sum(ctab.test[,2])
paste("Recall:",recall)

enrich <- precision / pnull
paste("Enrich:",enrich)
```


### 3.3 - Ajustamos el Umbral del modelo

Probamos con 45%, 55%, 60% y 65%. El mejor balance para las necesidades de negocio es con el 55%, con un buen balance entre precisión y exhaustividad.

```{r}
thresh <- 0.55
ctab.test <- table(prediccion=as.numeric(dfTestLR$pred > thresh), datos=dfTestLR$Approve)
ctab.test

precision <- ctab.test[2,2]/sum(ctab.test[2,])
paste("Precision:", precision)

recall <- ctab.test[2,2]/sum(ctab.test[,2])
paste("Recall:",recall)

enrich <- precision / pnull
paste("Enrich:",enrich)

PorcFalsosDetect <- ctab.test[1,1]/sum(ctab.test[,1])
PorcPositivosRech <- ctab.test[1,2]/sum(ctab.test[,2])
paste("% Falsos detectados: ", round(PorcFalsosDetect * 100, digits=2))
paste("% Creditos buenos rechazados: ", round(PorcPositivosRech * 100, digits=2))

```

### 3.4 - Que pasa si probamos contra el set de datos original?

Como ejercicio queremos saber que pasa si exponemos el modelo ajustado al set de datos original, para ver que resultados obtenemos.

```{r}
dfCreditCard$NAME_INCOME_TYPE[dfCreditCard$NAME_INCOME_TYPE == "Student"] <- "Working"

dfCreditCard$pred <- predict(modeloLR, newdata= dfCreditCard, type="response")
thresh <- 0.55
ctab.test <- table(prediccion=as.numeric(dfCreditCard$pred > thresh), datos=dfCreditCard$Approve)
ctab.test

precision <- ctab.test[2,2]/sum(ctab.test[2,])
paste("Precision:", precision)

recall <- ctab.test[2,2]/sum(ctab.test[,2])
paste("Recall:",recall)

enrich <- precision / pnull
paste("Enrich:",enrich)

PorcFalsosDetect <- ctab.test[1,1]/sum(ctab.test[,1])
PorcPositivosRech <- ctab.test[1,2]/sum(ctab.test[,2])
paste("% Falsos detectados: ", round(PorcFalsosDetect * 100, digits=2))
paste("% Creditos buenos rechazados: ", round(PorcPositivosRech * 100, digits=2))

```

El modelo de predicción funcionó bien para la detección de créditos buenos, no rechazó más de 1/4 de los mismos.

Sin embargo, no funcionó nada bien para la detección de créditos malos, solo pudo detectar un 30%.

# Análisis de Resultados y Conclusiones

Los objetivos que nos planteó el negocio fueron 2:
- detectar 2/3 de los créditos malos
- no perder más de 1/4 de créditos buenos

De acuerdo con el análisis realizado logramos ajustar un modelo que cumple mínimamente las necesidades de negocio propuestas para el dataset de testeo.

Se observa un modelo que no tiene grandes capacidades de predicción, es solamente mejor en un 34% que el modelo nulo.

Se partió de un set de datos muy desbalanceado, que obligó a aplicar la técnica SMOTE para obtener un balance para los sets de Entrenamiento y Testing.

Hicimos el ejercicio de probar el modelo contra el set de datos completo original, que no había sido utilizado de forma completa para el entrenamiento (por SMOTE) y observamos que no se comporta de acuerdo con las necesidades de negocio.

Por todo esto, entendemos que el proceso de Ciencia de Datos aplicado hasta el momento no logró un modelo que cumpla con el objetivo planteado.

Una primera solución podría ser tratar de conseguir un set de datos con mayor porcentaje de deudores. En este set solo se tiene información de 382 casos, que podría ser muy poco para que el algoritmo entrene correctamente.

También existen otros algoritmos de clasificación que podrían probarse con el set de datos actual como Arboles de Decisión, Random Forest o Support Vector Machines, y verificar si mejoran la capacidad de predicción.
